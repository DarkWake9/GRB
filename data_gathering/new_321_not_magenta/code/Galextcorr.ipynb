{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJ5e2K-6-eTr"
   },
   "source": [
    "# To use files from google drive, need to run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40644,
     "status": "ok",
     "timestamp": 1661474429060,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "ZCaq6OoL9dNe",
    "outputId": "5c92c633-06ad-4b73-f51b-da494f7f059a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1661486955673,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "ZlS1H9im-7fd",
    "outputId": "de6a7a19-c9c5-4fe7-9c93-9c5b4230b93f"
   },
   "outputs": [],
   "source": [
    "cd /content/drive//MyDrive/gamma-ray-gang/sample/For_system_galextcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1661486956319,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "bjw0a55R-9J6"
   },
   "outputs": [],
   "source": [
    "# Needed packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import timeit\n",
    "import urllib.request  \n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1661489092299,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "iCAdvZW8yVpz"
   },
   "outputs": [],
   "source": [
    "# In the reading location, put the folder that contains the subfolders (each subfolder is a GRB) such that the subfolders contain separate .txt files for each of the GCNs\n",
    "# reading_location     (GENERAL FOLDER WITH ALL GRBs)\n",
    "#                '--------> 001122        (SUBFOLDER WITH A GRB)\n",
    "#                                '-------> 001.txt       (TXT FILES EACH OF THEM IS A SEPARATE GCN FOR THE GRB 001122)\n",
    "#                                '-------> 002.txt       (...)\n",
    "\n",
    "\n",
    "\n",
    "reading_location = '/content/drive/.shortcut-targets-by-id/13erUG9K8SylY-kPvRLGrpy7p5SZLO9-g/gamma-ray-gang/sample/For_system_galextcorr/GCNs_opticalsample/'\n",
    "folderslist = [ f.path for f in os.scandir(reading_location) if f.is_dir() ] #going through all of the txt files inside the subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20084,
     "status": "ok",
     "timestamp": 1661496715443,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "Ax8fSRCGz2p-",
    "outputId": "fdee8d92-6cf3-4c22-987a-6314bd6aa0aa"
   },
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "positivelabel=['was corrected for galactic extinction','is corrected for galactic extinction',\n",
    "               'were corrected for galactic extinction', 'are corrected for galactic extinction',\n",
    "               'e(b-v)','E(B-V)','a(v)','a(b)','a(u)','a(r)','a(i)', 'E(B-V)', \"A_v\", \"A_V\", \"Av\", \"A_I\",\n",
    "              'a(V)','a(B)','a(U)','a(R)','a(I)','we assume \"typical\" ctio extinction coefficients',\n",
    "              'adopting the extinction curve of','the correct extinction values are',\n",
    "              'corrected for a large galactic extinction','corrected for extinction of',\n",
    "              'galactic extinction of','Corrected for the moderate Galactic foreground extinction',\n",
    "              'After correction for foreground extinction','galactic extinction at this location',\n",
    "              'In the extinction-corrected','assuming an SMC extinction law with',\n",
    "              'Corrected for the moderate Galactic foreground extinction',\n",
    "              'After correcting the interstellar extinction in our galaxy',\n",
    "              'galactic extinction in U band is',\n",
    "              'galactic extinction in B band is',\n",
    "              'galactic extinction in V band is',\n",
    "              'galactic extinction in R band is',\n",
    "              'galactic extinction in I band is',\n",
    "              'mag extinction in the observer frame V band assuming the mean Galactic dust+gas properties',\n",
    "              'After correcting for a Galactic foreground extinction corresponding to a reddening of',\n",
    "              'amount of SMC-like dust extinction',\n",
    "              'After correcting for the foreground galactic extinction of',\n",
    "              'Assuming an interstellar extinction obtained from',\n",
    "              'and foreground extinction in this direction is low',\n",
    "              'when taking into account the foreground Galactic extinction',\n",
    "              'We also note the large amount of foreground extinction',\n",
    "              'All the spectra have been corrected for the Galactic extinction',\n",
    "              'After correcting for the foreground reddening of',\n",
    "              'after correcting for galactic extinction',\n",
    "              'Galactic foreground extinction was taken to be',\n",
    "              'After correcting these magnitudes for the expected Galactic foreground extinction',\n",
    "              'After correcting for the Galactic extinction corresponding to a reddening of',\n",
    "              'and correcting for the (small) Galactic extinction',\n",
    "              'correcting for Galactic extinction',\n",
    "              'A standard Galactic extinction curve with',\n",
    "              'although Galactic extinction in this direction is significant',\n",
    "              'and Galactic extinction',\n",
    "              'with a small amount of SMC extinction',\n",
    "              'including SMC-like dust extinction',\n",
    "              'that includes the foreground Galactic extinction',\n",
    "              'broken power-law with a Milky Way extinction curve for the host extinction',\n",
    "              'The resulting spectrum has been corrected for Galactic extinction',\n",
    "              'corrected for a large galactic extinction',\n",
    "              'at this position the expected E(B-V) reddening due to the Galactic foreground is',\n",
    "              'passing through a galactic extinction of',\n",
    "              'galactic extinction a(',\n",
    "              'including the small galactic extinction',\n",
    "              'extinction corrected spectrum',\n",
    "              'the extinction coefficient was measured to be',  \"after the correction for the Galactic extinction\", \"which have been corrected for\",\n",
    "               \"when corrected for Galactic extinction\", \"a Galactic visual extinction along the line of sight\", \"Assuming no extinction\", \"adjusted by a Galactic extinction\",\n",
    "               \"correcting the observed b-r for the galactic extinction\", \"this location suffers from significant Galactic extinction\", \"Recall that Galactic extinction in this direction\",\n",
    "               \"notice an important Galactic extinction\", \"including the effects of Galactic extinction\", \"Due to a large Galactic extinction\", \"correcting for the small Galactic extinction\",\n",
    "               \"corrected for galactic extinction\", \"after correction for Galactic extinction\", \"The Galactic extinction along the line of sight is low\",\n",
    "               \"we assume a galactic extinction correction\", \"Galactic extinction included\", \"galactic extinction ar=02\"\n",
    "              ] \n",
    "negativelabel=[\"not corrected\", \"not been corrected\", \"No correction\", \"no correction\", \"without any correction\", \"without the galactic extinction correction\"\n",
    "               \"No Galactic extinction correction\",  \"which when corrected for galactic extinction has\", \"taking into account the high foreground Galactic extinction in the line of sight\",\n",
    "               \"very high excess N_H column density along the line of sight\", \"given the large galactic extinction towards this source\", \"uncorrected for Galactic extinction\", \n",
    "               \"did not apply Galactic extinction\", \"No Galactic extinction correction was applied\", \"without the galactic extinction correction\", \"on the galactic extinction curves\", \n",
    "               \"than can be accounted for by Galactic extinction\", \"not accounting for color terms or galactic foreground extinction\", \"most likely due to strong galactic dust extinction\",\n",
    "               \"did not correct for Galactic foreground extinction\", \"with no evidence for extinction by dust\", \"uncorrected for the expected Galactic extinction\",\n",
    "               \"uncorrected for the estimated Galactic extinction\", \"without correcting for the Galactic extinction\", \"no additional rest frame extinction\"]\n",
    "neg_flg=len(negativelabel)\n",
    "description=copy.deepcopy(negativelabel)\n",
    "description.extend(positivelabel)\n",
    "used=np.zeros(len(description))\n",
    "y_or_n_dict={}\n",
    "for i, grbid in enumerate(folderslist):\n",
    "    grb=grbid.replace(reading_location, \"\")\n",
    "    print('GRB ' + grb)\n",
    "    gcnslist=[g for g in glob.glob(grbid+\"/\"+\"*.txt\")]\n",
    "    for j, gcnid in enumerate(gcnslist):\n",
    "        gcn=gcnid.replace(reading_location, \"\")\n",
    "        dict_tmp={gcn: \"n\"}\n",
    "        with open(gcnid, errors=\"ignore\") as f:\n",
    "            lines=np.array(f.read().replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\").replace(\",\", \"\").split())\n",
    "            if (\"extinction\" in lines) and (\"galactic\" in lines or \"Galactic\" in lines):\n",
    "                ind=np.where(lines==\"extinction\")[0][0]\n",
    "                a=\" \".join(lines[ind-10:ind+10])\n",
    "                a_full=\" \".join(lines)\n",
    "                checksum= np.array([1 if des in a_full else 0 for des in description])\n",
    "                #print(checksum, gcn)\n",
    "                used += checksum\n",
    "                if sum(checksum)==0:\n",
    "                  print(a, gcn)\n",
    "                  dict_tmp={gcn: \"new\"}\n",
    "                elif sum(checksum) > 0 and checksum.nonzero()[0][0] >= neg_flg:\n",
    "                  #print(checksum.nonzero()[0][0], \"y\")\n",
    "                  dict_tmp[gcn]= \"y\"\n",
    "                elif sum(checksum) > 0 and checksum.nonzero()[0][0] < neg_flg:\n",
    "                  #print(checksum.nonzero()[0][0], \"n\")\n",
    "                  _=1\n",
    "                else:\n",
    "                  print(\"Error\")\n",
    "            y_or_n_dict= {**y_or_n_dict, **dict_tmp}\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(elapsed,' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1661496738979,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "pwlp8VN5RjfX",
    "outputId": "3322f6e0-5311-4268-8cd5-758e332cbace"
   },
   "outputs": [],
   "source": [
    "# number of files with correction \n",
    "cnt=0\n",
    "for s in y_or_n_dict.values():\n",
    "  if s == \"y\":\n",
    "    cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9447,
     "status": "ok",
     "timestamp": 1661503663725,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "-AVKL2oxMS-p",
    "outputId": "d62e486f-afd7-4d2a-dc3c-7f3e1b8dd67a"
   },
   "outputs": [],
   "source": [
    "# save dictionary as .txt file\n",
    "with open('/content/drive/.shortcut-targets-by-id/13erUG9K8SylY-kPvRLGrpy7p5SZLO9-g/gamma-ray-gang/sample/For_system_galextcorr/if_galextcorr.txt', 'w') as f:\n",
    "  print(\"GRB GCN galextcorr\\n\", file=f)\n",
    "  for k, v in y_or_n_dict.items():\n",
    "    print(k.split(sep=\"/\")[0], k.split(sep=\"/\")[1].replace(\".txt\", \"\"), v, \"\\n\", file=f)\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biagi\\Documents\\automatizeGRB\\test_for_Navonil\n"
     ]
    }
   ],
   "source": [
    "cd \"C:/Users/biagi/Documents/automatizeGRB/test_for_Navonil/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1661501353693,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "ycNhsoGAe2k4",
    "outputId": "31086e94-629b-47dc-9fa2-ace36f7ed320",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/biagi/Documents/automatizeGRB/test_for_Navonil\\000418A_arXiv_mag_regatheredBiagio.txt\n",
      "Checking  000418A ...\n",
      "C:/Users/biagi/Documents/automatizeGRB/test_for_Navonil\\050915A_gcn_mag_regatheredBiagio.txt\n",
      "Checking  050915A ...\n",
      "No contradiction!\n",
      "['C:/Users/biagi/Documents/automatizeGRB/test_for_Navonil\\\\000418A_arXiv_mag_regatheredBiagio.txt', 'C:/Users/biagi/Documents/automatizeGRB/test_for_Navonil\\\\050915A_gcn_mag_regatheredBiagio.txt']\n"
     ]
    }
   ],
   "source": [
    "# test if dictionary are in contradiction to written information\n",
    "\n",
    "y_or_n_dict={}\n",
    "with open(\"C:/Users/biagi/Documents/automatizeGRB/if_galextcorr.txt\") as f:\n",
    "    for line in f.readlines()[2::2]:\n",
    "        data = line.split(\" \")\n",
    "        key = str(data[0] + \"/\" + data[1] + \".txt\")\n",
    "        value=str(data[2])\n",
    "        dict_tmp={key: value}\n",
    "        y_or_n_dict= {**y_or_n_dict, **dict_tmp}\n",
    "        \n",
    "#print(y_or_n_dict)\n",
    "import sys\n",
    "checking_location= \"C:/Users/biagi/Documents/automatizeGRB/test_for_Navonil/*.txt\"\n",
    "checkdir=glob.glob(checking_location, recursive=True)\n",
    "checkdir=[i for i in checkdir if \"(\" not in i]\n",
    "add_files=[]\n",
    "cnt=0\n",
    "\n",
    "#print(checkdir)\n",
    "for filename in checkdir:\n",
    "  add_flg=1\n",
    "  grb_name=filename.split(sep=\"\\\\\")[-1].split(sep=\"_\")[0]\n",
    "  print(filename)\n",
    "  print(\"Checking \" , grb_name, \"...\")\n",
    "  with open(filename, \"r\") as f:\n",
    "    lines= f.readlines()\n",
    "  for line in lines:\n",
    "    if len(line.split()) == 0:\n",
    "      continue\n",
    "    if line.split()[-2] == \"y\" and line.split()[-1].isdigit():\n",
    "      add_flg=0\n",
    "      check_tmp= grb_name +  \"\\\\\" + line.split()[-1] + \".txt\"\n",
    "      try:\n",
    "        flg= (y_or_n_dict[check_tmp]==\"y\")\n",
    "        cnt += 1-flg\n",
    "        if flg==False:\n",
    "          print(\"Contradiction\", check_tmp)\n",
    "      except:\n",
    "        check_tmp=grb_name[:-1] + \"\\\\\" + line.split()[-1] + \".txt\"\n",
    "        flg= (y_or_n_dict[check_tmp]==\"y\")\n",
    "        cnt += 1-flg\n",
    "        if flg==False:\n",
    "          print(\"Contradiction\", check_tmp)\n",
    "    elif line.split()[-2] == \"n\" and line.split()[-1].isdigit():\n",
    "      add_flg=0\n",
    "      check_tmp= grb_name +  \"\\\\\" + line.split()[-1] + \".txt\"\n",
    "      try:\n",
    "        flg=(y_or_n_dict[check_tmp]== \"n\")\n",
    "        cnt += 1-flg\n",
    "        if flg==False:\n",
    "          print(\"Contradiction\", check_tmp)\n",
    "      except:\n",
    "        check_tmp=grb_name[:-1] + \"\\\\\" + line.split()[-1] + \".txt\"\n",
    "        flg= (y_or_n_dict[check_tmp]==\"n\")\n",
    "        cnt += 1-flg\n",
    "        if flg==False:\n",
    "          print(\"Contradiction\", check_tmp)\n",
    "  if filename not in add_files and add_flg==1:\n",
    "    add_files.append(filename)\n",
    "if cnt ==0:\n",
    "  print(\"No contradiction!\")\n",
    "print(checkdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1661501358029,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "JnI_9dABLbAt",
    "outputId": "4a75682a-6b11-497e-d773-316b699a81de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(checkdir))\n",
    "len(add_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1661506059284,
     "user": {
      "displayName": "Daisaburo KIDO",
      "userId": "00992552140896135411"
     },
     "user_tz": -540
    },
    "id": "Jo6u00YEI5Li",
    "outputId": "dc1798f7-0182-41bf-fb7f-392b4be24676",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 000418A...\n",
      "Processing 050915A...\n"
     ]
    }
   ],
   "source": [
    "# Adding correction if not existed\n",
    "for filename in add_files:\n",
    "  print(\"Processing \"+ filename.split(sep='\\\\')[-1].split(sep=\"_\")[0] + \"...\")\n",
    "  with open(filename, \"r\") as f:\n",
    "    lines= f.readlines()\n",
    "  with open(filename, \"w\") as f:\n",
    "    for i, line in enumerate(lines):\n",
    "      if i==0:\n",
    "        f.write(\"Time(s)\\tMag\\tMagErr\\tFilter\\tGalExtCorr\\tSource\\n\")\n",
    "        continue\n",
    "      try:\n",
    "        if len(line.split()) != 5:\n",
    "          for j in range(len(line.split())-1):\n",
    "            f.write(line.split()[j]+\"\\t\")\n",
    "          f.write(line.split()[-1]+\"\\n\")\n",
    "        else:\n",
    "          if line.split()[-1].isdigit():\n",
    "            check_tmp=filename.split(sep=\"/\")[-1].split(sep=\"_\")[0] + \"/\" + line.split()[-1] + \".txt\"\n",
    "            try:\n",
    "              print(y_or_n_dict[check_tmp])\n",
    "              for j in range(len(line.split())-1):\n",
    "                f.write(line.split()[j]+\"\\t\")\n",
    "              f.write(y_or_n_dict[check_tmp]+\"\\t\"+line.split()[-1]+\"\\n\")\n",
    "            except:\n",
    "              try:\n",
    "                check_tmp=filename.split(sep=\"/\")[-1].split(sep=\"_\")[0][:-1] + \"/\" + line.split()[-1] + \".txt\"\n",
    "                print(y_or_n_dict[check_tmp])\n",
    "                for j in range(len(line.split())-1):\n",
    "                  f.write(line.split()[j]+\"\\t\")\n",
    "                f.write(y_or_n_dict[check_tmp]+\"\\t\"+line.split()[-1]+\"\\n\")\n",
    "              except:\n",
    "                for j in range(len(line.split())-1):\n",
    "                  f.write(line.split()[j]+\"\\t\")\n",
    "                f.write(line.split()[-1]+\"\\n\")\n",
    "          else:\n",
    "            for j in range(len(line.split())-1):\n",
    "              f.write(line.split()[j]+\"\\t\")\n",
    "            f.write(line.split()[-1]+\"\\n\")\n",
    "      except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Galextcorr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
